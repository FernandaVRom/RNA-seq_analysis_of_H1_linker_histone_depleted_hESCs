---
title: "RNAseq_quality_assessment_and_processing_SKOs"
author: "Mukhtar Sadykov"
date: "12/1/2021"
---

# H1 KOs in human embryonic cells

## General overview

RNAseq read quality was assessed using FASTQC quality control tool [ref]. The reads were mapped to human GRCh38.p13 primary assembly using STAR (version 2.6.1) [ref]. Subsequently, gene counts were derived from the number of uniquely aligned unambiguous reads by Subread:featureCount (version v2.0.2) [ref] and library sizes were scale-normalized by the trimmed mean of M values (TMM) method using EdgeR software[ref]. The R package limma[ref] with the voomWithQualityWeights function [ref] was utilized to calculate the weighted likelihoods for all samples, based on the observed mean–variance relationship of every gene and sample. Genes with fold change greater than two and false discovery rate corrected p-value (Benjamini-Hochberg procedure) < 0.05 were considered to be differentially expressed.

## Preprocessing of a count table

Clean the environment, install the libraries and set working directory.
```{r}
rm(list=ls())
pacman::p_load(limma, Glimma, edgeR, AnnotationDbi,org.Hs.eg.db, EnsDb.Hsapiens.v86, tidyverse, ggplot2, ... = gridExtra, ggrepel, reshape2, EnhancedVolcano, GGally, sva, pheatmap)
```

Visualize MDS of the raw data 
```{r}
cts  <- read.csv("./Data/SKOs.csv", row.names = 1) # dim is 60663 x 33
rownames_cts<- row.names(cts)
study <- read.csv("./Data/meta_SKOs.csv", row.names=1) # dim is 33 x 2

raw <- edgeR::DGEList(counts=cts, samples=study)
mdf <- limma::plotMDS(cpm(raw, log=T), top=nrow(raw), plot=F, dim.plot = c(1,2), var.explained = TRUE)
mdf <- data.frame(Comp1=mdf$x, Comp2=mdf$y, 
      lab=colnames(raw), 
      Tx=raw$samples$Tx)
p1 <- ggplot(mdf, aes(x=Comp1, y=Comp2, label=lab, col=Tx)) +
  geom_point() +
  geom_text_repel() +
  ggtitle("MDS plot of RAW H1's SKO's") +
  theme(legend.position="top")+ theme_classic()
```


### Batch normalization

Since the samples were collected in different times, and libraries were made separately, it is important to adjust for batch effect. ComBatSeq ([Zhang et al., 2020. NAR](https://urldefense.com/v3/__https://doi.org/10.1093/nargab/lqaa078__;!!Nmw4Hv0!ycgzUCXcFHGhQEnI2H47axDZcJtl7u1xv3mdW2lj-zw3lXmUe2fAPNVM9_db1ABe3hR1QDHrBz5cdvOgBfnGAV0a7_-IGozu-kLL8GmJ9U2k$ )) was used for that purpose. It uses a negative binomial regression model that retains the integer nature of count data in RNA-seq studies, making the batch adjusted data compatible with common differential expression software packages that require integer counts.

Batch normalized data will be used to plot MDS plots.

```{r}
sample_names = names(cts)[1:length(names(cts))]

# define conditions, library methods, and replicates
conditions = c("SKO_0","SKO_0","SKO_0","SKO_0",
      "SKO_1","SKO_1","SKO_1","SKO_1",
      "SKO_2","SKO_2","SKO_2","SKO_2",
      "SKO_3","SKO_3","SKO_3","SKO_3",
      "SKO_4","SKO_4","SKO_4","SKO_4",
      "SKO_5","SKO_5","SKO_5","SKO_5",
      "SKO_X","SKO_X","SKO_X","SKO_X",
      "WT","WT","WT","WT","WT")
library_methods = c("Batch9","Batch9","Batch7","Batch7",
     "Batch9","Batch9","Batch7","Batch7",
     "Batch9","Batch9","Batch7","Batch7",
     "Batch9","Batch9","Batch7","Batch7",
     "Batch9","Batch9","Batch7","Batch7",
     "Batch9","Batch9","Batch7","Batch7",
     "Batch9","Batch9","Batch7","Batch7",
     "Batch7","Batch7","Batch7","Batch8","Batch8")
replicates = c(1, 2, 3, 4,
      1, 2, 3, 4, 
      1, 2, 3, 4, 
      1, 2, 3, 4, 
      1, 2, 3, 4, 
      1, 2, 3, 4, 
      1, 2, 3, 4, 
      1, 2, 3, 4, 5)
```

Perform the batch correction
```{r}
groups = sapply(as.character(conditions), switch, "SKO_0" = 1, "SKO_1" = 2,"SKO_2" = 3, "SKO_3" = 4,"SKO_4" = 5, "SKO_5" = 6,"SKO_X" = 7, "WT" = 8)
batches = sapply(as.character(library_methods), switch, "Batch9" = 1, "Batch7" = 2,"Batch8" = 3, USE.NAMES = F)
corrected_data = sva::ComBat_seq(counts = as.matrix(cts[,sample_names]), batch = library_methods, group = groups)
```

```{r}
batch_norm <- edgeR::DGEList(counts=corrected_data, samples=study)

mdf2 <- limma::plotMDS(cpm(batch_norm, log=T), top=nrow(batch_norm), plot=F, dim.plot = c(1,2), var.explained = TRUE)
mdf2 <- data.frame(Comp1=mdf2$x, Comp2=mdf2$y, 
      lab=colnames(batch_norm), 
      Tx=batch_norm$samples$Tx)
p2 <- ggplot(mdf2, aes(x=Comp1, y=Comp2, label=lab, col=Tx)) +
  geom_point() +
  geom_text_repel() +
  ggtitle("MDS plot of batch normalized H1's KO's") +
  theme(legend.position="top")+ theme_classic()

grid.arrange(p1, p2, nrow = 2)
```
## Make DGEList

Before making the DGE list it is convinient to have symbol version of the genes in addition to ENSGID.

```{r}
ensg <- sub("\\..*", "", rownames(cts))  # remove version number in case you have it
sym <- AnnotationDbi::mapIds(EnsDb.Hsapiens.v86, keys=ensg,
        column="SYMBOL", keytype="GENEID") # Unable to map 3533 of 60663 requested IDs.
gene <- data.frame(ENSGID=ensg, SYMBOL=sym, stringsAsFactors=F)
rownames(gene) <- rownames(cts)
```


```{r}
# Check point of the dimensions of datasets
stopifnot( identical( colnames(cts), rownames(study) ) )
stopifnot( identical( rownames(cts), rownames(gene) ) )

raw <- edgeR::DGEList(counts=cts, samples=study, genes=gene)
```


```{r}
# Check for bias in sequencing depth by KO types.
ggplot(raw$samples, aes(x=Tx, y=lib.size/1000000)) + 
  geom_boxplot() + geom_point() +
  xlab("") + ylab("") + ggtitle("Sequencing library size (millions)") 
```

## Filter

To filter the low expression genes the edgeR's filterByExpr() was used.
Default min number of reads to keep is 10.
```{r}
sum(keep <- edgeR::filterByExpr(raw, group=raw$samples$Tx))  ## 60663 -> 28611 
```

```{r}
raw_filtered <- raw[keep, , keep.lib.sizes=FALSE]
```
After changing the number of genes from 60663 to 28611, the lib.sizes will be recalculated to be the sum of the counts left in the rows of the experiment for each sample, with keep.lib.sizes = FALSE

Plot the intensities before and after filtering
```{r}
tmp <- edgeR::cpm(raw, log=TRUE) %>% melt  ##log2 values returned
g.before <- ggplot(tmp, aes(value, col=Var2)) + geom_density() + 
  ggtitle("Before filtering") + theme_bw() + theme(legend.position="none")

tmp <- edgeR::cpm(raw_filtered, log=TRUE) %>% melt
g.after <- ggplot(tmp, aes(value, col=Var2)) + geom_density() + 
  ggtitle("After filtering") + theme_bw() + theme(legend.position="none") 

grid.arrange(g.before, g.after, nrow=1)

rm( list=setdiff(ls(), c("raw_filtered", "study")) )
```

## Normalization

The edgeR function calcNormFactors was used to generate and apply normalization factors. By default, the M-values are weighted according to inverse variances, as computedby the delta method for logarithms of binomial random variables. If refColumn is unspecified, then the library whose upper quartile is closest to the mean upper quartile is used.

```{r}
# Calculate normalization factors to scale the raw library sizes.
norm <- edgeR::calcNormFactors(raw_filtered, method="TMM")

nf <- norm$samples$norm.factors # for each sample
range(nf) # 0.7827566 to 1.1650883
o <- order(nf)

boxplot( cpm(raw_filtered[ , o], log=T), xaxt="n", main="Before TMM normalization")
boxplot( cpm(norm[ , o], log=T),   xaxt="n", main="After TMM normalization")

plot( norm$samples$norm.factors[o],  xaxt="n", main="Normalization factor", xlab="" )
```

# Analysis of RNAseq
## DEGs

```{r}
#study_outlier <- read.delim("meta_outlier.txt", row.names=1)
mm <- model.matrix( ~ 0 + Tx + Batch, data=norm$samples)
colnames(mm) <- gsub("Tx", "", colnames(mm))
colnames(mm) <- gsub("BatchBatch", "Batch", colnames(mm))
head(mm,10)

```

## Limma-voom
Allows for incredibly flexible model specification (you can include multiple categorical and continuous variables, allowing incorporation of almost any kind of metadata)

Based on simulation studies, maintains the false discovery rate at or below the nominal rate, unlike some other packages

The above specifies a model where each coefficient corresponds to a KO's mean

```{r}
vm <- limma::voomWithQualityWeights(norm, design=mm, plot=T)
```
What is voom doing?

Counts are transformed to log2 counts per million reads (CPM), where “per million reads” is defined based on the normalization factors we calculated earlier
A linear model is fitted to the log2 CPM for each gene, and the residuals are calculated
A smoothed curve is fitted to the sqrt(residual standard deviation) by average expression (see red line in plot above)
The smoothed curve is used to obtain weights for each gene and sample that are passed into limma along with the log2 CPMs.
More details at https://urldefense.com/v3/__https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29__;!!Nmw4Hv0!ycgzUCXcFHGhQEnI2H47axDZcJtl7u1xv3mdW2lj-zw3lXmUe2fAPNVM9_db1ABe3hR1QDHrBz5cdvOgBfnGAV0a7_-IGozu-kLL8LEHEdV9$ 


Another handy feature of limma-voom  is easy to make contrast matrices
## Contrast matrix
```{r}
cm <- limma::makeContrasts(
  H1.0vWT = SKO_0 - WT,
  H1.1vWT = SKO_1 - WT,
  H1.2vWT = SKO_2 - WT,
  H1.3vWT = SKO_3 - WT,
  H1.4vWT = SKO_4 - WT,
  H1.5vWT = SKO_5 - WT,
  H1.XvWT = SKO_X - WT,
  levels= mm )
```

## Fitting
### what is eBayes
### Empirical Bayes Statistics for Differential Expression
### Given a microarray linear model fit, compute moderated t-statistics, moderated F-statistic, and log-odds of differential expression by empirical Bayes moderation of the standard errors towards a common value.

Empirical Bayes smoothing of gene-wise standard deviations provides increased power.


```{r}
fit <- limma::lmFit(vm[ , rownames(mm) ], mm) # lmFit fits a linear model using weighted least squares for each gene
fit <- limma::contrasts.fit(fit, cm) # Estimate contrast for each gene
fit <- limma::eBayes(fit, trend=TRUE) # Empirical Bayes smoothing of standard errors (shrinks standard errors that are much larger or smaller than those from other genes towards the average standard error) (see https://urldefense.com/v3/__https://www.degruyter.com/doi/10.2202/1544-6115.1027__;!!Nmw4Hv0!ycgzUCXcFHGhQEnI2H47axDZcJtl7u1xv3mdW2lj-zw3lXmUe2fAPNVM9_db1ABe3hR1QDHrBz5cdvOgBfnGAV0a7_-IGozu-kLL8Nt1J23i$ )
```

## Summary tables for H1 KOs

Identify which genes are significantly differentially expressed for each contrast from a fit object containing p-values and test statistics. 
```{r}
summary(limma::decideTests(fit)) # Default p valut is 0.05.
```

Some studies require more than an adjusted p-value cut-off. For a stricter definition on significance, one may require log-fold-changes (log-FCs) to be above a minimum value.

Here we introduced three significance level to the topTable: sig0, sig1 and sig2.
sig0's -1 means that the gene is significantly downregulated (see parameters in the code); sig0's +1 meand that the gene is significantly upregulated (see parameters in the code);
sig1 and sig2 values are even stricter.

## Toptable

```{r}
# Created two significance levels: sig and sig2. Sig based on FC and FDR.
tt1 <- topTable(fit, coef="H1.0vWT", adjust.method="fdr", n=Inf) %>% 
  rownames_to_column("ID") %>% 
  arrange(P.Value) %>% 
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>% 
  dplyr::select(ID, ENSGID, SYMBOL, 
    H1.0vWT_LFC=logFC, H1.0vWT_P=P.Value, H1.0vWT_FDR=adj.P.Val, H1.0vWT_sig0=sig0, H1.0vWT_sig1=sig1,H1.0vWT_sig2=sig2)
head(tt1)

tt2 <- topTable(fit, coef="H1.1vWT", adjust.method="fdr", n=Inf) %>%
  rownames_to_column("ID") %>%
  arrange(P.Value) %>%
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>%
  dplyr::select(ID, ENSGID, SYMBOL,
    H1.1vWT_LFC=logFC, H1.1vWT_P=P.Value, H1.1vWT_FDR=adj.P.Val, H1.1vWT_sig0=sig0, H1.1vWT_sig1=sig1,H1.1vWT_sig2=sig2)


tt3 <- topTable(fit, coef="H1.2vWT", adjust.method="fdr", n=Inf) %>%
  rownames_to_column("ID") %>%
  arrange(P.Value) %>%
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>%
  dplyr::select(ID, ENSGID, SYMBOL,
    H1.2vWT_LFC=logFC, H1.2vWT_P=P.Value, H1.2vWT_FDR=adj.P.Val, H1.2vWT_sig0=sig0, H1.2vWT_sig1=sig1,H1.2vWT_sig2=sig2)


tt4 <- topTable(fit, coef="H1.3vWT", adjust.method="fdr", n=Inf) %>% 
  rownames_to_column("ID") %>% 
  arrange(P.Value) %>% 
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>% 
  dplyr::select(ID, ENSGID, SYMBOL, 
    H1.3vWT_LFC=logFC, H1.3vWT_P=P.Value, H1.3vWT_FDR=adj.P.Val, H1.3vWT_sig0=sig0, H1.3vWT_sig1=sig1,H1.3vWT_sig2=sig2)

tt5 <- topTable(fit, coef="H1.4vWT", adjust.method="fdr", n=Inf) %>% 
  rownames_to_column("ID") %>% 
  arrange(P.Value) %>% 
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>% 
  dplyr::select(ID, ENSGID, SYMBOL, 
    H1.4vWT_LFC=logFC, H1.4vWT_P=P.Value, H1.4vWT_FDR=adj.P.Val, H1.4vWT_sig0=sig0, H1.4vWT_sig1=sig1,H1.4vWT_sig2=sig2)

tt6 <- topTable(fit, coef="H1.5vWT", adjust.method="fdr", n=Inf) %>% 
  rownames_to_column("ID") %>% 
  arrange(P.Value) %>% 
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>% 
  dplyr::select(ID, ENSGID, SYMBOL, 
    H1.5vWT_LFC=logFC, H1.5vWT_P=P.Value, H1.5vWT_FDR=adj.P.Val, H1.5vWT_sig0=sig0, H1.5vWT_sig1=sig1,H1.5vWT_sig2=sig2)

tt7 <- topTable(fit, coef="H1.XvWT", adjust.method="fdr", n=Inf) %>% 
  rownames_to_column("ID") %>% 
  arrange(P.Value) %>% 
  mutate(sig0  = sign(logFC)*( abs(logFC) > log2(1.5) & adj.P.Val < 0.05 ),
   sig1  = sign(logFC)*( abs(logFC) > log2(2) & adj.P.Val < 0.05 ),
   sig2 = sign(logFC)*( abs(logFC) > log2(4) & adj.P.Val < 0.01 )) %>% 
  dplyr::select(ID, ENSGID, SYMBOL, 
    H1.XvWT_LFC=logFC, H1.XvWT_P=P.Value, H1.XvWT_FDR=adj.P.Val, H1.XvWT_sig0=sig0, H1.XvWT_sig1=sig1, H1.XvWT_sig2=sig2)

tt <- BiocGenerics::Reduce(plyr::join, list(tt1, tt2, tt3, tt4, tt5, tt6, tt7))
#rm(list=setdiff(ls(), c("norm", "tt", "vm")))

# save tt
write.csv(tt, file="./Results/topTable_SKOs.csv", quote=F, row.names=F)
```


## Volcano plots

```{r}
pdf(file="./Results/volcano_plots_FDR_001.pdf", height=10, width=10)

lfc_tmp <- max( -log10(tt$H1.0vWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.0vWT_LFC", y="H1.0vWT_FDR", 
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    #selectLab = c("IGF1",	"PITX2",	"GATA2",	"NKX2-5",	"CLEC2A",	"ZFPM2",	"KLRF2",	"CX3CL1",	"EGR3",	"TEK",	"CCBE1",	"H1F0",	"LHX5"),
    drawConnectors = TRUE,
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.0_KO vs WT") +
  theme(legend.position="none")

lfc_tmp <- max( -log10(tt$H1.1vWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.1vWT_LFC", y="H1.1vWT_FDR", 
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    #selectLab = c("IGF1",	"MIXL1",	"PITX2",	"LHX1",	"NKX2-5",	"CLEC2A",	"KLRF2",	"CX3CL1",	"ULBP1",	"WNT7B",	"HIST1H1A",	"TEK"),
    drawConnectors = TRUE,
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.1_KO vs WT") +
  theme(legend.position="none")

lfc_tmp <- max( -log10(tt$H1.2vWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.2vWT_LFC", y="H1.2vWT_FDR", 
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    drawConnectors = TRUE,
    #selectLab = c("IGF1",	"RELN",	"PRAME",	"CLEC2A",	"KLRF2",	"CX3CL1",	"ULBP1",	"PTPRO",	"CYP26B1",	"HIST1H1C"),
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.2_KO vs WT") +
  theme(legend.position="none")

lfc_tmp <- max( -log10(tt$H1.3vWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.3vWT_LFC", y="H1.3vWT_FDR", 
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    #selectLab = c("EVI2B",	"CLEC2A",	"KLRF2",	"YJEFN3",	"EGR1",	"KMO",	"CYP46A1",	"DPEP1",	"NOXRED1",	"C4B",	"HIST1H1D",	"H1FX",	"H1F0",	"HIST1H1A",	"HIST1H1C",	"HIST1H1E",	"HIST1H1B",	"MALAT1"),
    drawConnectors = TRUE,
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.3_KO vs WT") +
  theme(legend.position="none")

lfc_tmp <- max( -log10(tt$H1.4vWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.4vWT_LFC", y="H1.4vWT_FDR",
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    #selectLab = c("RP4-686C3.7", "TBX3",	"PRAME",	"FRZB",	"CYP26A1",	"SIX6",	"SHISA2",	"CLEC2A",	"KLK14",	"KLRF2",	"CDKN1A",	"GDF15",	"CER1",	"HIST1H1E"),
    drawConnectors = TRUE,
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.4_KO vs WT") +
  theme(legend.position="none")

lfc_tmp <- max( -log10(tt$H1.5vWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.5vWT_LFC", y="H1.5vWT_FDR",
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    #selectLab = c("PITX2",	"IGF1",	"ADRA2A",	"TEK",	"EMX1",	"CX3CL1",	"LMX1B",	"WNT7B",	"NKX2-5",	"GDF15",	"LHX5",	"SIX3",	"HIST1H1A",	"HIST1H1B",	"H1F0"),
    drawConnectors = TRUE,
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.5_KO vs WT") +
  theme(legend.position="none")

lfc_tmp <- max( -log10(tt$H1.XvWT_FDR) )
EnhancedVolcano(tt, lab=tt$SYMBOL,
    x="H1.XvWT_LFC", y="H1.XvWT_FDR",
    pCutoff=0.01, ylim=c(0, lfc_tmp+2),
    #selectLab = c("EVI2B",	"CLEC2A",	"KLK14",	"KLRF2",	"CX3CL1",	"C3",	"STX1A",	"SEC31B",	"ALAS2",	"MAPK15",	"H1FX",	"HIST1H1C",	"HIST1H1D",	"HIST1H1E",	"HIST1H1B",	"SIX6",	"MALAT1"),
    drawConnectors = TRUE,
    ylab = bquote(~-Log[10] ~ italic( "adjusted p-value")),
    title="H1.X_KO vs WT") +
  theme(legend.position="none")
dev.off()
```

## The list of genes that are Up or Down regulated. 
```{r}
# Function to write a table
mywrite <- function(...){
  write.table(..., row.names=F, col.names=F, quote=F)
}

tt %>% dplyr::filter(H1.0vWT_sig==1) %>% arrange(H1.0vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.0vWT_up.txt")
tt %>% dplyr::filter(H1.0vWT_sig==-1) %>% arrange(H1.0vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.0vWT_down.txt")

tt %>% dplyr::filter(H1.1vWT_sig==1) %>% arrange(H1.1vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.1vWT_up.txt")
tt %>% dplyr::filter(H1.1vWT_sig==-1) %>% arrange(H1.1vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.1vWT_down.txt")

tt %>% dplyr::filter(H1.2vWT_sig==1) %>% arrange(H1.2vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.2vWT_up.txt")
tt %>% dplyr::filter(H1.2vWT_sig==-1) %>% arrange(H1.2vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.2vWT_down.txt")

tt %>% dplyr::filter(H1.3vWT_sig==1) %>% arrange(H1.3vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.3vWT_up.txt")
tt %>% dplyr::filter(H1.3vWT_sig==-1) %>% arrange(H1.3vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.3vWT_down.txt")

tt %>% dplyr::filter(H1.4vWT_sig==1) %>% arrange(H1.4vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.4vWT_up.txt")
tt %>% dplyr::filter(H1.4vWT_sig==-1) %>% arrange(H1.4vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.4vWT_down.txt")

tt %>% dplyr::filter(H1.5vWT_sig==1) %>% arrange(H1.5vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.5vWT_up.txt")
tt %>% dplyr::filter(H1.5vWT_sig==-1) %>% arrange(H1.5vWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.5vWT_down.txt")

tt %>% dplyr::filter(H1.XvWT_sig==1) %>% arrange(H1.XvWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.XvWT_up.txt")
tt %>% dplyr::filter(H1.XvWT_sig==-1) %>% arrange(H1.XvWT_LFC) %>% 
  pull(ENSGID) %>% mywrite(file="./Results/siglist_H1.XvWT_down.txt")
```

## The union of DEGs between all the samples. 
```{r}
h10_sig_up <- tt %>% dplyr::filter(H1.0vWT_sig0==1) %>% arrange(H1.0vWT_LFC) %>% 
  pull(ENSGID) #get the names of DEGs with FDR<0.05 and FC 1.5
h10_sig_down <- tt %>% dplyr::filter(H1.0vWT_sig0==-1) %>% arrange(H1.0vWT_LFC) %>% 
  pull(ENSGID)

h11_sig_up <- tt %>% dplyr::filter(H1.1vWT_sig0==1) %>% arrange(H1.1vWT_LFC) %>% 
  pull(ENSGID)
h11_sig_down <- tt %>% dplyr::filter(H1.1vWT_sig0==-1) %>% arrange(H1.1vWT_LFC) %>% 
  pull(ENSGID)

h12_sig_up <- tt %>% dplyr::filter(H1.2vWT_sig0==1) %>% arrange(H1.2vWT_LFC) %>% 
  pull(ENSGID)
h12_sig_down <- tt %>% dplyr::filter(H1.2vWT_sig0==-1) %>% arrange(H1.2vWT_LFC) %>% 
  pull(ENSGID)

h13_sig_up <- tt %>% dplyr::filter(H1.3vWT_sig0==1) %>% arrange(H1.3vWT_LFC) %>% 
  pull(ENSGID)
h13_sig_down <- tt %>% dplyr::filter(H1.3vWT_sig0==-1) %>% arrange(H1.3vWT_LFC) %>% 
  pull(ENSGID)

h14_sig_up <- tt %>% dplyr::filter(H1.4vWT_sig0==1) %>% arrange(H1.4vWT_LFC) %>% 
  pull(ENSGID)
h14_sig_down <- tt %>% dplyr::filter(H1.4vWT_sig0==-1) %>% arrange(H1.4vWT_LFC) %>% 
  pull(ENSGID)

h15_sig_up <- tt %>% dplyr::filter(H1.5vWT_sig0==1) %>% arrange(H1.5vWT_LFC) %>% 
  pull(ENSGID)
h15_sig_down <- tt %>% dplyr::filter(H1.5vWT_sig0==-1) %>% arrange(H1.5vWT_LFC) %>% 
  pull(ENSGID)

h1x_sig_up <- tt %>% dplyr::filter(H1.XvWT_sig0==1) %>% arrange(H1.XvWT_LFC) %>% 
  pull(ENSGID)
h1x_sig_down <- tt %>% dplyr::filter(H1.XvWT_sig0==-1) %>% arrange(H1.XvWT_LFC) %>% 
  pull(ENSGID)

# Find the union of all the genes in the table
union_of_genes <- BiocGenerics::Reduce(union, list(h10_sig_up, h10_sig_down, h11_sig_up, h11_sig_down, h12_sig_up, h12_sig_down, h13_sig_up, h13_sig_down, h14_sig_up, h14_sig_down, h15_sig_up, h15_sig_down, h1x_sig_up, h1x_sig_down)) # find the union from all conditions

union_topTable <- dplyr::filter(tt, ID %in% union_of_genes) # gives you toptable with union
dim(union_topTable) # 11098 x 45

write.csv(union_topTable, file="./Results/union_topTable_SKOs.csv", quote=F, row.names=F)
```


